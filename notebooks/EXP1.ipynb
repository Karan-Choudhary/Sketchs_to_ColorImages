{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\kc510\\\\Documents\\\\Projects\\\\Project_iNeuron\\\\Sketch_To_Color_Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "\n",
    "epochs=100\n",
    "buffer_size=6000\n",
    "batch_size=4\n",
    "img_width = 256\n",
    "img_height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "    image = tensorflow.io.read_file(image_file)\n",
    "    image = tensorflow.image.decode_png(image)\n",
    "\n",
    "    w = tensorflow.shape(image)[1]\n",
    "    print(w)\n",
    "\n",
    "    w = w // 2\n",
    "    real_image = image[:, :w, :]\n",
    "    input_image = image[:, w:, :]\n",
    "\n",
    "    input_image = tensorflow.cast(input_image, tensorflow.float32)\n",
    "    real_image = tensorflow.cast(real_image, tensorflow.float32)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tensorflow.image.resize(input_image, [height, width],\n",
    "                                          tensorflow.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tensorflow.image.resize(real_image, [height, width],\n",
    "                                          tensorflow.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(input_image, real_image):\n",
    "    stacked_image = tensorflow.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tensorflow.image.random_crop(\n",
    "        stacked_image, size=[2, img_height, img_width, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorflow.function\n",
    "def random_jitter(input_image,real_image):\n",
    "    input_image, real_image = resize(input_image,real_image,286,286)\n",
    "    input_image, real_image = random_crop(input_image,real_image)\n",
    "\n",
    "    if tensorflow.random.uniform(())>0.5:\n",
    "        input_image = tensorflow.image.flip_left_right(input_image)\n",
    "        real_image = tensorflow.image.flip_left_right(real_image)\n",
    "    \n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def load_image_train(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = random_jitter(input_image,real_image)\n",
    "    input_image, real_image = normalize(input_image,real_image)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "train_dataset = tensorflow.data.Dataset.list_files(path+'\\\\train\\\\*.png')\n",
    "train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tensorflow.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def load_image_test(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = resize(input_image,real_image,img_width,img_height)\n",
    "    input_image, real_image = normalize(input_image,real_image)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "test_dataset = tensorflow.data.Dataset.list_files(path+'\\\\val\\\\*.png')\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "def downsample(filters,size,shape,apply_batchnorm=True):\n",
    "    initializer = tensorflow.random_normal_initializer(0.,0.02)\n",
    "\n",
    "    result = tensorflow.keras.Sequential()\n",
    "    result.add(tensorflow.keras.layers.Conv2D(filters,size,strides=2,padding='same',\n",
    "                                                kernel_initializer=initializer,\n",
    "                                                batch_input_shape=shape,\n",
    "                                                use_bias=False))\n",
    "    \n",
    "    if apply_batchnorm:\n",
    "        result.add(tensorflow.keras.layers.BatchNormalization())\n",
    "    \n",
    "    result.add(tensorflow.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def upsmaple(filters,size,shape,apply_dropout=False):\n",
    "    initializer = tensorflow.random_normal_initializer(0.,0.02)\n",
    "\n",
    "    result = tensorflow.keras.Sequential()\n",
    "    result.add(tensorflow.keras.layers.Conv2DTranspose(filters,size,strides=2,padding='same',\n",
    "                                                kernel_initializer=initializer,\n",
    "                                                batch_input_shape=shape,\n",
    "                                                use_bias=False))\n",
    "    \n",
    "    result.add(tensorflow.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tensorflow.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tensorflow.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGenerator():\n",
    "    inputs = tensorflow.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64,4, (None,256,256,3), apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128,4, (None,128,128,64)),\n",
    "        downsample(256,4, (None,64,64,128)),\n",
    "        downsample(512,4, (None,32,32,256)),\n",
    "        downsample(512, 4, (None,16,16,512)),\n",
    "        downsample(512, 4, (None,8,8,512)),\n",
    "        downsample(512,4, (None, 4,4,512)),\n",
    "        downsample(512, 4, (None,2,2,512))\n",
    "    ]\n",
    "\n",
    "    upstack = [\n",
    "        upsmaple(512,4,(None,1,1,512), apply_dropout=True),\n",
    "        upsmaple(512,4,(None,2,2,1024), apply_dropout=True),\n",
    "        upsmaple(512,4,(None,4,4,1024), apply_dropout=True),\n",
    "        upsmaple(512,4,(None,8,8,1024)),\n",
    "        upsmaple(256,4,(None,16,16,1024)),\n",
    "        upsmaple(128,4,(None,32,32,512)),\n",
    "        upsmaple(64,4,(None,64,64,256))\n",
    "    ]\n",
    "\n",
    "    initializer = tensorflow.random_normal_initializer(0.,0.02)\n",
    "    last = tensorflow.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS,4,strides=2,padding='same',kernel_initializer=initializer,activation='tanh')\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    skips=[]\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    for up, skip in zip(upstack,skips):\n",
    "        x = up(x)\n",
    "        x = tensorflow.keras.layers.Concatenate()([x,skip])\n",
    "    \n",
    "    x = last(x)\n",
    "\n",
    "    return tensorflow.keras.Model(inputs=inputs,outputs=x)\n",
    "\n",
    "generator = buildGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downs(filters,size,apply_batchnorm=False):\n",
    "    initializer = tensorflow.random_normal_initializer(0.,0.02)\n",
    "\n",
    "    result = tensorflow.keras.Sequential()\n",
    "    result.add(tensorflow.keras.layers.Conv2D(filters,size,strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tensorflow.keras.layer.BatchNormalization())\n",
    "\n",
    "    result.add(tensorflow.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def buildDescriminator():\n",
    "    initializer = tensorflow.random_normal_initializer(0.,0.02)\n",
    "\n",
    "    inp = tensorflow.keras.layers.Input(shape=[256,256,3],name='input_image')\n",
    "    tar = tensorflow.keras.layers.Input(shape=[256,256,3],name='target_image')\n",
    "\n",
    "    x = tensorflow.keras.layers.concatenate([inp,tar])\n",
    "\n",
    "    down1 = downs(64,4,False)(x)\n",
    "    down2 = downs(128,4)(down1)\n",
    "    down3 = downs(256,4)(down2)\n",
    "\n",
    "    zero_pad1 = tensorflow.keras.layers.ZeroPadding2D()(down3)\n",
    "    conv = tensorflow.keras.layers.Conv2D(512,4,strides=1,kernel_initializer=initializer,use_bias=False)(zero_pad1)\n",
    "\n",
    "    batchnorm1 = tensorflow.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tensorflow.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tensorflow.keras.layers.ZeroPadding2D()(leaky_relu)\n",
    "\n",
    "    last = tensorflow.keras.layers.Conv2D(1,4,strides=1,kernel_initializer=initializer)(zero_pad2)\n",
    "\n",
    "    return tensorflow.keras.Model(inputs=[inp,tar],outputs=last)\n",
    "\n",
    "discriminator = buildDescriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tensorflow.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "LAMBDA = 100\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tensorflow.ones_like(disc_generated_output),disc_generated_output)\n",
    "\n",
    "    l1_loss = tensorflow.reduce_mean(tensorflow.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tensorflow.ones_like(disc_real_output),disc_real_output)\n",
    "    generated_loss = loss_object(tensorflow.zeros_like(disc_generated_output),disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tensorflow.keras.optimizers.Adam(2e-4,beta_1=0.5)\n",
    "discriminator_optimizer = tensorflow.keras.optimizers.Adam(2e-4,beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '.\\\\notebooks\\\\training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt\")\n",
    "checkpoint = tensorflow.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                                                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                                                                generator=generator,\n",
    "                                                                                discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model,test_input,tar):\n",
    "    prediction = model(test_input,training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0],tar[0],prediction[0]]\n",
    "    title = [\"Input Image\", \"Ground Truth\",\"Predicted Image\"]\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i]*0.5+0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"notebooks\\\\logs\\\\\"\n",
    "summary_writer = tensorflow.summary.create_file_writer(\n",
    "    log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorflow.function\n",
    "def train_step(input_image,target,epoch):\n",
    "    with tensorflow.GradientTape() as gen_tape, tensorflow.GradientTape() as disc_tape:\n",
    "        \n",
    "        gen_out = generator(input_image,training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image,target],training=True)\n",
    "        disc_generated_output = discriminator([input_image,gen_out],training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output,gen_out,target)\n",
    "        disc_loss = discriminator_loss(disc_real_output,disc_generated_output)\n",
    "    \n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,discriminator.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tensorflow.summary.scalar('gen_total_loss',gen_total_loss,step=epoch)\n",
    "        tensorflow.summary.scalar('gen_gan_loss',gen_gan_loss,step=epoch)\n",
    "        tensorflow.summary.scalar('gen_l1_loss',gen_l1_loss,step=epoch)\n",
    "        tensorflow.summary.scalar('disc_loss',disc_loss,step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for n, (input_image,target) in train_ds.enumerate():\n",
    "            print(\".\",end=\" \")\n",
    "            if (n+1)%100==0:\n",
    "                print('n+1=',n+1)\n",
    "            train_step(input_image,target,epoch)\n",
    "        print()\n",
    "\n",
    "        if (epoch+1)%5==0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print('Time taken for epoch {} is {} sec\\n'.format(epoch+1,time.time()-start))\n",
    "\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(100, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(200, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(300, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(400, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(500, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(600, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(700, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(800, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(900, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1000, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1100, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1200, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1300, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1400, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1500, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1600, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1700, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1800, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(1900, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2000, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2100, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2200, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2300, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2400, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2500, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2600, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2700, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2800, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(2900, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(3000, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(3100, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(3200, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(3300, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(3400, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(3500, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Time taken for epoch 1 is 16999.257167816162 sec\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(100, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(200, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(300, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(400, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(500, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(600, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(700, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(800, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . n+1= tf.Tensor(900, shape=(), dtype=int64)\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . "
     ]
    }
   ],
   "source": [
    "fit(train_dataset,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "578ce72e72bd9f13049fd4c13d9f5b1c81715c13ddea0a3c61ff70756cb5d6d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
